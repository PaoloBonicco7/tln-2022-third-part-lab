{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "   \"Natural language processing is the process of converting a natural language into a computer language.\",\n",
    "   \"Machine learning is the process of learning from data.\",\n",
    "   \"Machine learning is the process of applying statistical algorithms to the data.\",\n",
    "   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    stoplist = set('for a of the and to in'.split(' '))\n",
    "    texts = [[word for word in document.lower().split() if word not in stoplist] for document in corpus]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(texts):  \n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 2), (3, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 2), (6, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1)]]\n"
     ]
    }
   ],
   "source": [
    "texts = tokenize(text_corpus)\n",
    "frequency = get_frequency(texts)\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.707*\"learning\" + -0.500*\"data.\" + -0.500*\"machine\" + 0.000*\"is\" + 0.000*\"language\" + -0.000*\"natural\" + 0.000*\"process\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) \n",
    "\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "'''for doc in corpus_tfidf:\n",
    "    print(doc)'''\n",
    "\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=1)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "\n",
    "lsi_model.print_topics(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
