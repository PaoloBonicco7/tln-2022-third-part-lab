{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appunti:Prendo le def\n",
    "calcolo i termini più frequenti\n",
    "faccio disambiguation\n",
    "ottengo synset piu frequenti - che saranno i possibili genus\n",
    "confronto\n",
    "Il punto è non cofrontare tutte le definizioni (100K+) ma confrontarle solo con i genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_sense_disambiguation(list_words, word):\n",
    "    right_synset = lesk(list_words, word)\n",
    "    return right_synset\n",
    "\n",
    "def remove_stop_words(row):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = [',', '.', ';', '!', '?', \"'\", \"''\", '\"', \"’\", \"’’\", \"`\",\"``\"]\n",
    "    filtered_sentence = [w for w in row if not w.lower() in stop_words and w not in punctuation]\n",
    "    return filtered_sentence\n",
    "\n",
    "def calculate_frequency(row):\n",
    "    freq_dict = {}\n",
    "    row = remove_stop_words(word_tokenize(row))\n",
    "    for word in row[1:]:\n",
    "        if word.lower() not in freq_dict:\n",
    "            freq_dict[word.lower()] = 1\n",
    "        else:\n",
    "            freq_dict[word.lower()] += 1\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ('feeling', 10) \n",
      "[Synset('feeling.n.01'), Synset('impression.n.01'), Synset('spirit.n.02'), Synset('feeling.n.04'), Synset('touch.n.10'), Synset('feeling.n.06'), Synset('feel.v.01'), Synset('find.v.05'), Synset('feel.v.03'), Synset('feel.v.04'), Synset('feel.v.05'), Synset('feel.v.06'), Synset('feel.v.07'), Synset('feel.v.08'), Synset('feel.v.09'), Synset('palpate.v.01'), Synset('feel.v.11'), Synset('feel.v.12'), Synset('feel.v.13')]\n",
      "Word: ('human', 8) \n",
      "[Synset('homo.n.02'), Synset('human.a.01'), Synset('human.a.02'), Synset('human.a.03')]\n",
      "Word: ('feel', 8) \n",
      "[Synset('feel.n.01'), Synset('spirit.n.02'), Synset('tactile_property.n.01'), Synset('feel.n.04'), Synset('feel.v.01'), Synset('find.v.05'), Synset('feel.v.03'), Synset('feel.v.04'), Synset('feel.v.05'), Synset('feel.v.06'), Synset('feel.v.07'), Synset('feel.v.08'), Synset('feel.v.09'), Synset('palpate.v.01'), Synset('feel.v.11'), Synset('feel.v.12'), Synset('feel.v.13')]\n",
      "Word: ('something', 6) \n",
      "[]\n",
      "Word: ('state', 4) \n",
      "[Synset('state.n.01'), Synset('state.n.02'), Synset('state.n.03'), Synset('state.n.04'), Synset('state_of_matter.n.01'), Synset('state.n.06'), Synset('country.n.02'), Synset('department_of_state.n.01'), Synset('state.v.01'), Synset('submit.v.02'), Synset('express.v.04')]\n",
      "[('feeling', 10), ('human', 8), ('feel', 8), ('something', 6), ('state', 4)]\n",
      "Word: ('human', 26) \n",
      "[Synset('homo.n.02'), Synset('human.a.01'), Synset('human.a.02'), Synset('human.a.03')]\n",
      "Word: ('homo', 5) \n",
      "[Synset('homosexual.n.01'), Synset('homo.n.02')]\n",
      "Word: ('person', 4) \n",
      "[Synset('person.n.01'), Synset('person.n.02'), Synset('person.n.03')]\n",
      "Word: ('sapiens', 4) \n",
      "[Synset('sapiens.a.01')]\n",
      "Word: ('living', 3) \n",
      "[Synset('life.n.02'), Synset('living.n.02'), Synset('animation.n.01'), Synset('support.n.06'), Synset('populate.v.01'), Synset('live.v.02'), Synset('survive.v.01'), Synset('exist.v.02'), Synset('be.v.11'), Synset('know.v.05'), Synset('live.v.07'), Synset('living.a.01'), Synset('living.s.02'), Synset('living.s.03'), Synset('surviving.s.01'), Synset('living.s.05'), Synset('living.s.06')]\n",
      "[('human', 26), ('homo', 5), ('person', 4), ('sapiens', 4), ('living', 3)]\n",
      "Word: ('someone', 15) \n",
      "[Synset('person.n.01')]\n",
      "Word: ('feeling', 7) \n",
      "[Synset('feeling.n.01'), Synset('impression.n.01'), Synset('spirit.n.02'), Synset('feeling.n.04'), Synset('touch.n.10'), Synset('feeling.n.06'), Synset('feel.v.01'), Synset('find.v.05'), Synset('feel.v.03'), Synset('feel.v.04'), Synset('feel.v.05'), Synset('feel.v.06'), Synset('feel.v.07'), Synset('feel.v.08'), Synset('feel.v.09'), Synset('palpate.v.01'), Synset('feel.v.11'), Synset('feel.v.12'), Synset('feel.v.13')]\n",
      "Word: ('anger', 7) \n",
      "[Synset('anger.n.01'), Synset('anger.n.02'), Synset('wrath.n.02'), Synset('anger.v.01'), Synset('anger.v.02')]\n",
      "Word: ('action', 6) \n",
      "[Synset('action.n.01'), Synset('action.n.02'), Synset('military_action.n.01'), Synset('natural_process.n.01'), Synset('action.n.05'), Synset('action.n.06'), Synset('action.n.07'), Synset('legal_action.n.01'), Synset('action.n.09'), Synset('action.n.10'), Synset('action.v.01'), Synset('carry_through.v.01')]\n",
      "Word: ('something', 6) \n",
      "[]\n",
      "[('someone', 15), ('feeling', 7), ('anger', 7), ('action', 6), ('something', 6)]\n",
      "Word: ('used', 22) \n",
      "[Synset('use.v.01'), Synset('use.v.02'), Synset('use.v.03'), Synset('use.v.04'), Synset('practice.v.04'), Synset('use.v.06'), Synset('used.a.01'), Synset('exploited.s.02'), Synset('secondhand.s.02')]\n",
      "Word: ('object', 15) \n",
      "[Synset('object.n.01'), Synset('aim.n.02'), Synset('object.n.03'), Synset('object.n.04'), Synset('object.n.05'), Synset('object.v.01'), Synset('object.v.02')]\n",
      "Word: ('build', 12) \n",
      "[Synset('physique.n.01'), Synset('human_body.n.01'), Synset('construct.v.01'), Synset('build_up.v.02'), Synset('build.v.03'), Synset('build.v.04'), Synset('build.v.05'), Synset('build.v.06'), Synset('build.v.07'), Synset('build.v.08'), Synset('build_up.v.04'), Synset('build.v.10')]\n",
      "Word: ('material', 11) \n",
      "[Synset('material.n.01'), Synset('material.n.02'), Synset('fabric.n.01'), Synset('material.n.04'), Synset('material.n.05'), Synset('material.s.01'), Synset('material.a.02'), Synset('material.a.03'), Synset('material.s.04'), Synset('corporeal.a.01'), Synset('substantial.a.03')]\n",
      "Word: ('construction', 11) \n",
      "[Synset('construction.n.01'), Synset('construction.n.02'), Synset('construction.n.03'), Synset('structure.n.01'), Synset('construction.n.05'), Synset('construction.n.06'), Synset('construction.n.07')]\n",
      "[('used', 22), ('object', 15), ('build', 12), ('material', 11), ('construction', 11)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open ('../def.csv', 'r') as f:\n",
    "    for row in f:\n",
    "        dict = calculate_frequency(row)\n",
    "        k = Counter(dict)\n",
    "        most_freq = k.most_common(5)\n",
    "        \n",
    "        for word in most_freq:\n",
    "            print(f\"Word: {word} \\n{wn.synsets(word[0])}\")\n",
    "        print(most_freq)\n",
    "        #synset.lexname()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26ed4aba4c119105743730e2b96c2b24e70aa5572a8c25f5746c820738ee0ea5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
