{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impementazione dell'esercizio sulla test segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step algoritmo:\n",
    "\n",
    "- Dividere il file per righe, le righe guideranno l'esercizio in quanto ai tali ci sarà associata la riga di riferimento;\n",
    "- Contare il valore di co-occorrenza per ogni frase:\n",
    "  - Il valore di co-occorrenza è la somma dei valori di co-occorrenza per ogni parola in una frase;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (ita)\n",
    "* 36/37 - taglio arg 1/2\n",
    "* 56/57 - taglio arg 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (en)\n",
    "\n",
    "- 59/60\n",
    "- 102/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.test.utils import simple_preprocess\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_ita(phrase):\n",
    "    stop_words = stopwords.words('italian')\n",
    "    phrase = phrase.split()\n",
    "    phrase = [word for word in phrase if word not in stop_words]\n",
    "    return phrase\n",
    "\n",
    "def get_text_from_file(path):\n",
    "    file = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open (path, 'r') as f:\n",
    "        for row in f:\n",
    "            filtered_s = [w for w in word_tokenize(row) if not w.lower() in stop_words]\n",
    "            file.append(simple_preprocess(str(filtered_s), deacc=True))\n",
    "    f.close()\n",
    "    return file\n",
    "\n",
    "def cooccurrence(text):\n",
    "    '''\n",
    "    Calculates the cooccurrence value of a sequence of words. \n",
    "    This value correspond to the sum of the occurrences of the n most frequently used words in the word list.\n",
    "    '''\n",
    "    score = 0\n",
    "    c = Counter()\n",
    "    most_common = []\n",
    "    for row in text:\n",
    "        c.update(row)\n",
    "        \n",
    "    most_common = c.most_common(3)\n",
    "    # print(most_common)\n",
    "    \n",
    "    for el in most_common:\n",
    "        score = score + el[1]\n",
    "        \n",
    "    return score\n",
    "\n",
    "def extract_segment(file, start, end):\n",
    "    '''\n",
    "    Given the first and the last line, extract the segment.\n",
    "    '''\n",
    "    segment = []\n",
    "    for i in range(start, end):\n",
    "        segment.append(file[i])\n",
    "    return segment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizziamo le parole in una lista di liste, in qui ogni lista corrisponderà alle parole di una riga tokenizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 3133: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\Università\\Magistrale\\TLN\\PART 3\\tln-2022-third-part-lab\\es4_segmentation\\segmentopol.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000008?line=0'>1</a>\u001b[0m file \u001b[39m=\u001b[39m get_text_from_file(\u001b[39m'\u001b[39;49m\u001b[39m../res/segmentation_eng.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000008?line=1'>2</a>\u001b[0m c \u001b[39m=\u001b[39m Counter()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000008?line=2'>3</a>\u001b[0m num_lines \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../res/segmentation_eng.txt\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m# Number of lines in the file\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\Università\\Magistrale\\TLN\\PART 3\\tln-2022-third-part-lab\\es4_segmentation\\segmentopol.ipynb Cell 6'\u001b[0m in \u001b[0;36mget_text_from_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000005?line=8'>9</a>\u001b[0m stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000005?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m (path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000005?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000005?line=11'>12</a>\u001b[0m         filtered_s \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m word_tokenize(row) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m w\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m stop_words]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/PART%203/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000005?line=12'>13</a>\u001b[0m         file\u001b[39m.\u001b[39mappend(simple_preprocess(\u001b[39mstr\u001b[39m(filtered_s), deacc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_decode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 3133: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "file = get_text_from_file('../res/segmentation_eng.txt')\n",
    "c = Counter()\n",
    "num_lines = sum(1 for line in open('../res/segmentation_eng.txt')) # Number of lines in the file\n",
    "\n",
    "for row in file:\n",
    "    c.update(row)\n",
    "    \n",
    "print(c.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramethers tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo dei valori standard per i tagli iniziali, per farlo divido il totale delle linee per il numero di topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 60, 120, 181]\n"
     ]
    }
   ],
   "source": [
    "cut = []\n",
    "n_topic = 3\n",
    "\n",
    "cut.append(0)\n",
    "for k in range(1, n_topic):\n",
    "    cut.append(num_lines // n_topic * k)\n",
    "cut.append(num_lines)\n",
    "\n",
    "print(cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo il valore di cooccorrenza per ogni segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "45\n",
      "[7, 64, 105]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "cut = [0 , 3, 45, num_lines]\n",
    "# Extract the segments\n",
    "for i in range(len(cut)-1):\n",
    "    print(cut[i])\n",
    "    text = extract_segment(file, cut[i], cut[i+1])\n",
    "    scores.append(cooccurrence(text))\n",
    "    \n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First implementation of the complete algorithm - DIDN'T WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores, scores = [0, 0, 0], [0, 0, 0]\n",
    "sum_score = 0\n",
    "max = 0\n",
    "# cut = [0, 10, 45, num_lines]\n",
    "\n",
    "#* Questi parametri sono legati alle singole iterazioni, quindi alla ricerca dei tagli legati ai singoli segmenti\n",
    "limit = [0, 0, 0] # Used to avoid to go to far away from the cut\n",
    "direction = [1, 1, 1] # Indicate the direction of the search, 1 mean \"top\" and -1 mean \"bottom\"\n",
    "\n",
    "cut = [0, 40, 120, num_lines] #* Real: [59, 102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo la somma di tutti gli score (dei 3 segmenti) e cerchiamo di massimizzarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Max values is [70, 95, 47] at lines [0, 45, 123, 181]\n"
     ]
    }
   ],
   "source": [
    "# Extract the segments\n",
    "for f in range(2000):    \n",
    "    \n",
    "    for i in range(len(cut)-1):\n",
    "        text = extract_segment(file, cut[i], cut[i+1])\n",
    "        scores[i] = cooccurrence(text)\n",
    "        \n",
    "    sum_scores = sum(scores)\n",
    "    if(sum_scores > max):\n",
    "        max = sum_scores\n",
    "    \n",
    "    # Check the score and update the max for each segment\n",
    "    for k in range(len(cut)-1):\n",
    "        \n",
    "        # Find the cut for the first segments wich is special because have just 1 boundary\n",
    "        if k == 0:\n",
    "            if(scores[k] > max_scores[k]):\n",
    "                max_scores[k] = scores[k]\n",
    "                limit[k] = 0\n",
    "            # Update the value of cut --> Try a direction\n",
    "            elif limit[k] < 5:\n",
    "                cut[1] = cut[1] + (1 * direction[k])\n",
    "                limit[k] = limit[k] + 1\n",
    "            # Change direction of search --> Wrong direction\n",
    "            else:\n",
    "                direction[k] *= -1\n",
    "                limit[k] = 0\n",
    "        else:     \n",
    "            if scores[k] > max_scores[k]:\n",
    "                max_scores[k] = scores[k]\n",
    "                limit[k] = 0\n",
    "            elif limit[k] < 5:\n",
    "                cut[k] = cut[k] + (1 * direction[k])\n",
    "                limit[k] = limit[k] + 1\n",
    "            else: # Update the cut point\n",
    "                direction[k] = direction[k] * -1\n",
    "                limit[k] = 0\n",
    "                cut[k] = cut[k] + (1 * direction[k])\n",
    "        \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n The Max values is {max_scores} at lines {cut}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second implementation of the complete algorithm: Maximise the sum of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best cut at lines \n",
      "[0, 59, 102, 181]\n",
      " the max sum is \n",
      "231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the segments\n",
    "x , y, max = 0, 0, 0\n",
    "max_scores = [(0, 0), (0, 0), (0, 0)]\n",
    "max_cut = []\n",
    "\n",
    "for f in range(20000): \n",
    "    \n",
    "    y = random.randint(2, num_lines-1)\n",
    "    x = random.randint(1, num_lines-2)\n",
    "    \n",
    "    while x > y:\n",
    "        y = random.randint(2, num_lines-1)\n",
    "        x = random.randint(1, num_lines-2)\n",
    "    \n",
    "    cut = [0, x, y, num_lines]\n",
    "    \n",
    "    for i in range(len(cut)-1):\n",
    "        text = extract_segment(file, cut[i], cut[i+1])\n",
    "        scores[i] = cooccurrence(text)\n",
    "        \n",
    "    sum_scores = sum(scores)\n",
    "    if(sum_scores > max):\n",
    "        max = sum_scores\n",
    "        max_cut = cut\n",
    "    \n",
    "    for d in range(len(scores)):\n",
    "        max_scores[d] = (cut[d], scores[d])\n",
    "        \n",
    "        \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n Best cut at lines \\n{max_cut}\\n the max sum is \\n{max}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best cut for first segment - Funziona solo con un punto di partenza inferiore al toglio corretto (59) in quanto non c'è un limite \"destro\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Max value is: 80 at line 59\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores.append(0)\n",
    "max_scores = (0, 0)\n",
    "cut = [0, 10, 45, num_lines]\n",
    "limit = 0 # Used to avoid to go to far away from the cut\n",
    "direction = 1 # Indicate the direction of the search, 1 mean \"top\" and -1 mean \"bottom\"\n",
    "\n",
    "# Extract the segments\n",
    "for f in range(1000):\n",
    "    text = extract_segment(file, cut[0], cut[1])\n",
    "    scores[0] = cooccurrence(text)\n",
    "    \n",
    "    # print(scores)\n",
    "        \n",
    "    # Save the max value and the cut line --> Good value found\n",
    "    if(scores[0] > max_scores[1]):\n",
    "        max_scores = (cut[1], scores[0])\n",
    "        limit = 0\n",
    "        \n",
    "    # Update the value of cut --> Try a direction\n",
    "    elif limit < 5:\n",
    "        cut[1] = cut[1] + (1 * direction)\n",
    "        limit = limit + 1\n",
    "    \n",
    "    # Change direction of search --> Wrong direction\n",
    "    else:\n",
    "        direction *= -1\n",
    "        limit = 0\n",
    "\n",
    "    \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n The Max value is: {max_scores[1]} at line {max_scores[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
