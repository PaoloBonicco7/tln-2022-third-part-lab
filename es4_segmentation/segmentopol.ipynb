{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impementazione dell'esercizio sulla test segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step algoritmo:\n",
    "\n",
    "- Dividere il file per righe, le righe guideranno l'esercizio in quanto ai tali ci sarà associata la riga di riferimento;\n",
    "- Contare il valore di co-occorrenza per ogni frase:\n",
    "  - Il valore di co-occorrenza è la somma dei valori di co-occorrenza per ogni parola in una frase;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (ita)\n",
    "* 36/37 - taglio arg 1/2\n",
    "* 56/57 - taglio arg 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (en)\n",
    "\n",
    "- 59/60\n",
    "- 102/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.test.utils import simple_preprocess\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_ita(phrase):\n",
    "    stop_words = stopwords.words('italian')\n",
    "    phrase = phrase.split()\n",
    "    phrase = [word for word in phrase if word not in stop_words]\n",
    "    return phrase\n",
    "\n",
    "def get_text_from_file(path):\n",
    "    file = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open (path, 'r') as f:\n",
    "        for row in f:\n",
    "            filtered_s = [w for w in word_tokenize(row) if not w.lower() in stop_words]\n",
    "            file.append(simple_preprocess(str(filtered_s), deacc=True))\n",
    "    f.close()\n",
    "    return file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date due frasi ritorna il valore di cooccorrenza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizziamo le parole in una lista di liste, in qui ogni lista corrisponderà alle parole di una riga tokenizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quantum', 63), ('gorilla', 34), ('gorillas', 31), ('classical', 16), ('algorithm', 16), ('silverback', 15), ('females', 14), ('computers', 14), ('males', 13), ('computer', 13), ('algorithms', 13), ('male', 12), ('also', 12), ('problems', 12), ('western', 11), ('ft', 11), ('years', 10), ('mountain', 10), ('known', 10), ('computing', 10), ('eastern', 9), ('groups', 9), ('kg', 8), ('troops', 8), ('lowland', 8), ('adult', 8), ('may', 8), ('tend', 7), ('live', 7), ('model', 7)]\n"
     ]
    }
   ],
   "source": [
    "file = get_text_from_file('../res/segmentation_eng.txt')\n",
    "c = Counter()\n",
    "num_lines = sum(1 for line in open('../res/segmentation_eng.txt')) # Number of lines in the file\n",
    "\n",
    "for row in file:\n",
    "    c.update(row)\n",
    "    \n",
    "print(c.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo il valore di cooccorrenza per ogni segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cut is at line:  28\n",
      "[('gorillas', 17), ('gorilla', 12), ('ft', 11), ('kg', 8), ('species', 6), ('western', 5), ('wild', 5), ('lb', 5), ('adult', 5), ('eastern', 4), ('living', 4), ('arm', 4), ('live', 4), ('lowland', 4), ('male', 4), ('forests', 3), ('africa', 3), ('humans', 3), ('metres', 3), ('called', 3)] [('quantum', 63), ('gorilla', 22), ('classical', 16), ('algorithm', 16), ('gorillas', 14), ('computers', 14), ('females', 13), ('computer', 13), ('algorithms', 13), ('also', 12), ('silverback', 12), ('problems', 12), ('males', 11), ('computing', 10), ('known', 9), ('groups', 9), ('mountain', 8), ('male', 8), ('years', 7), ('may', 7)]\n"
     ]
    }
   ],
   "source": [
    "cut = random.randint(0, num_lines)\n",
    "c1,c2 = Counter(), Counter()\n",
    "i=1\n",
    "\n",
    "for row in file:\n",
    "    if(i < cut):\n",
    "        c1.update(row)\n",
    "    else:\n",
    "        c2.update(row)\n",
    "        \n",
    "    i+=1\n",
    "\n",
    "print(\"The cut is at line: \", cut)\n",
    "print(c1.most_common(20), c2.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file2list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../res/segmentation.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000003?line=1'>2</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000003?line=2'>3</a>\u001b[0m     \u001b[39m# Trasformo il file in una lista di liste di parole, la lista di parole corrisponde alla frase\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000003?line=3'>4</a>\u001b[0m     s \u001b[39m=\u001b[39m file2list(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000003?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(s)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file2list' is not defined"
     ]
    }
   ],
   "source": [
    "with open('../res/segmentation.txt', 'r') as f:\n",
    "    \n",
    "    # Trasformo il file in una lista di liste di parole, la lista di parole corrisponde alla frase\n",
    "    s = file2list(f)\n",
    "    print(s)\n",
    "    # length_p = len(s)\n",
    "    # # Calcolo la cooccorrenza tra le frasi\n",
    "    # cooc = cooccorence(s)\n",
    "    # # print(cooc)\n",
    "    # n_tagli = 3\n",
    "    # tagli = pos_tagli(length_p, n_tagli)\n",
    "    \n",
    "    # val = [0, 0, 0]\n",
    "    # for i in range(1, len(val)+1): # 3\n",
    "    #     for j in range(tagli[i-1], tagli[i]): # in base a quante righe ci sono nel prima del taglio\n",
    "    #         val[i] = val[i] + cooc[j][0]\n",
    "            \n",
    "    # print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venvdicaro': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc711e4ee2b6550a1e55fb58a23702f691a325dedbbea2e10fa55c056de4b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
