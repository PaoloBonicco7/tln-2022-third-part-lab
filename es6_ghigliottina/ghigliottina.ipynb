{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tempo:\n",
    "- ammazzare \n",
    "\n",
    "- ingannare \n",
    "\n",
    "- pioggia \n",
    "\n",
    "- mele \n",
    "\n",
    "- spazio\n",
    "\n",
    "Cercare le parole nelle frasi del dataset, restiruire le frasi che le cotnengono.\n",
    "pulire le frasi ottenute, per restituire \"tempo\" da \"ammazzare il tempo\" (stopwords e initialwords)\n",
    "restituirer la parola più frequente tra quelle restituite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con', 'col', 'coi', 'da', 'dal', 'dallo', 'dai', 'dagli', 'dall', 'dagl', 'dalla', 'dalle', 'di', 'del', 'dello', 'dei', 'degli', 'dell', 'degl', 'della', 'delle', 'in', 'nel', 'nello', 'nei', 'negli', 'nell', 'negl', 'nella', 'nelle', 'su', 'sul', 'sullo', 'sui', 'sugli', 'sull', 'sugl', 'sulla', 'sulle', 'per', 'tra', 'contro', 'io', 'tu', 'lui', 'lei', 'noi', 'voi', 'loro', 'mio', 'mia', 'miei', 'mie', 'tuo', 'tua', 'tuoi', 'tue', 'suo', 'sua', 'suoi', 'sue', 'nostro', 'nostra', 'nostri', 'nostre', 'vostro', 'vostra', 'vostri', 'vostre', 'mi', 'ti', 'ci', 'vi', 'lo', 'la', 'li', 'le', 'gli', 'ne', 'il', 'un', 'uno', 'una', 'ma', 'ed', 'se', 'perché', 'anche', 'come', 'dov', 'dove', 'che', 'chi', 'cui', 'non', 'più', 'quale', 'quanto', 'quanti', 'quanta', 'quante', 'quello', 'quelli', 'quella', 'quelle', 'questo', 'questi', 'questa', 'queste', 'si', 'tutto', 'tutti', 'a', 'c', 'e', 'i', 'l', 'o', 'ho', 'hai', 'ha', 'abbiamo', 'avete', 'hanno', 'abbia', 'abbiate', 'abbiano', 'avrò', 'avrai', 'avrà', 'avremo', 'avrete', 'avranno', 'avrei', 'avresti', 'avrebbe', 'avremmo', 'avreste', 'avrebbero', 'avevo', 'avevi', 'aveva', 'avevamo', 'avevate', 'avevano', 'ebbi', 'avesti', 'ebbe', 'avemmo', 'aveste', 'ebbero', 'avessi', 'avesse', 'avessimo', 'avessero', 'avendo', 'avuto', 'avuta', 'avuti', 'avute', 'sono', 'sei', 'è', 'siamo', 'siete', 'sia', 'siate', 'siano', 'sarò', 'sarai', 'sarà', 'saremo', 'sarete', 'saranno', 'sarei', 'saresti', 'sarebbe', 'saremmo', 'sareste', 'sarebbero', 'ero', 'eri', 'era', 'eravamo', 'eravate', 'erano', 'fui', 'fosti', 'fu', 'fummo', 'foste', 'furono', 'fossi', 'fosse', 'fossimo', 'fossero', 'essendo', 'faccio', 'fai', 'facciamo', 'fanno', 'faccia', 'facciate', 'facciano', 'farò', 'farai', 'farà', 'faremo', 'farete', 'faranno', 'farei', 'faresti', 'farebbe', 'faremmo', 'fareste', 'farebbero', 'facevo', 'facevi', 'faceva', 'facevamo', 'facevate', 'facevano', 'feci', 'facesti', 'fece', 'facemmo', 'faceste', 'fecero', 'facessi', 'facesse', 'facessimo', 'facessero', 'facendo', 'sto', 'stai', 'sta', 'stiamo', 'stanno', 'stia', 'stiate', 'stiano', 'starò', 'starai', 'starà', 'staremo', 'starete', 'staranno', 'starei', 'staresti', 'starebbe', 'staremmo', 'stareste', 'starebbero', 'stavo', 'stavi', 'stava', 'stavamo', 'stavate', 'stavano', 'stetti', 'stesti', 'stette', 'stemmo', 'steste', 'stettero', 'stessi', 'stesse', 'stessimo', 'stessero', 'stando']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_1 = ['ammazzare', 'ingannare', 'pioggia', 'mele', 'spazio']\n",
    "WORDS_2 = ['bicchiere', 'mulino', 'gocce', 'gola', 'buco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_ita(phrase):\n",
    "    stop_words = stopwords.words('italian')\n",
    "    phrase = phrase.split()\n",
    "    phrase = [word for word in phrase if word not in stop_words]\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(path, words):\n",
    "    phrases = []    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            for word in words:\n",
    "                if word.lower() in line.lower():  # Salviamo le frasi che contengono le parole in input\n",
    "                    line = line.lower()\n",
    "                    line = line.replace(word, '')\n",
    "                    phrases.append(remove_stop_words_ita(line)) # Rimuoviamo dalla frase le stopword e le parole in input\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_words(phrases):\n",
    "    words = {}\n",
    "    for phrase in phrases:\n",
    "        for word in phrase:\n",
    "            if word in words:\n",
    "                words[word] += 1\n",
    "            else:\n",
    "                words[word] = 1\n",
    "    return words\n",
    "\n",
    "def get_most_frequent_word(words):\n",
    "    max_word = ''\n",
    "    max_count = 0\n",
    "    for word in words:\n",
    "        if words[word] > max_count:\n",
    "            max_word = word\n",
    "            max_count = words[word]\n",
    "    return max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['acqua'], ['staffa'], ['fare', 'acqua'], ['re', 'pollice'], ['andare', 'buca', '/'], ['avere', 'cuore'], ['avere', 'carte', 're'], ['avere', 'groppo'], ['acqua'], ['nero'], ['genio', 'sretezza'], ['acqua'], ['mandare', 'acquaio'], ['mentire'], ['peccato'], ['perdersi', 'd', 'acqua'], ['pietra', 'anre', '/', 'pietra', 'd', 'angolo'], ['portare', 'acqua', 'proprio'], ['prendere'], ['somigliarsi', 'due', 'd', 'acqua'], ['strappo', 're'], ['tempesta', 'd', 'acqua'], ['tirare', 'acqua', 'proprio']]\n",
      "{'acqua': 9, 'staffa': 1, 'fare': 1, 're': 3, 'pollice': 1, 'andare': 1, 'buca': 1, '/': 2, 'avere': 3, 'cuore': 1, 'carte': 1, 'groppo': 1, 'nero': 1, 'genio': 1, 'sretezza': 1, 'mandare': 1, 'acquaio': 1, 'mentire': 1, 'peccato': 1, 'perdersi': 1, 'd': 4, 'pietra': 2, 'anre': 1, 'angolo': 1, 'portare': 1, 'proprio': 2, 'prendere': 1, 'somigliarsi': 1, 'due': 1, 'strappo': 1, 'tempesta': 1, 'tirare': 1}\n",
      "\n",
      "La sesta parola è: acqua\n"
     ]
    }
   ],
   "source": [
    "ph = check_dataset('..\\ghigliottina.txt', WORDS_2)\n",
    "print(ph)\n",
    "dict = most_frequent_words(ph)\n",
    "print(dict)\n",
    "answer = get_most_frequent_word(dict)\n",
    "print(f\"\\nLa sesta parola è: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
