{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consegna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scegliere un verbo transitivo --> **KILL**\n",
    "- Trovare un corpus con > 1000 frasi in cui comprare un verbo scelto (usare un verbo comune) --> link to resource: https://sentence.yourdictionary.com/kill\n",
    "- Effettuare parsing e disambiguazione\n",
    "- Usare i supersensi di wordnet sugli argomenti (subj e obj nel caso di 2 argomenti) del verbo scelto\n",
    "- Calcolo risultati, frequenza e stampare cluster semantici ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande per il prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il modo in ci etichettiamo \"person\" alle parole va bene?\n",
    "- Il modo in cui disambiguiamo, per quanto poco efficiente (lesk), Ã¨ ok?\n",
    "- Va bene il modo in cui rappresentiamo i risultati (cluster semantici)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appunti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet supersense: Per ogni sinset abbiamo un supersenso associato (esempi su slide)\n",
    "Utilizzare i supersense dei synset per determinare il semantic type - nltk\n",
    "\n",
    "I supersense di wordenet non sono il massimo, vediamo alcune alternative:\n",
    " * CSI - Ai supersense ci sono associati delle categorie che possono essere utilizzati come supersense\n",
    "\n",
    "link to wordnet resource: https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html\n",
    "\n",
    "*Spunti futuri:*\n",
    "\n",
    "**Come distinguo i synset?**\n",
    "--> Funzione lesk (https://www.nltk.org/howto/wsd.html#word-sense-disambiguation)\n",
    "\n",
    "**Come trovo il supersenso tra due termini?**\n",
    "--> Funzione Lowest Common Hypernyms (https://www.nltk.org/howto/wordnet_lch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from nltk.wsd import lesk\n",
    "import re\n",
    "import spacy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* person: Usata per trovare il supersenso dei pronomi\n",
    "* patter: Usato per trovare il soggetto e l'oggetto del verbo kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = [\"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"me\", \"him\", \"her\", \"his\", \"them\", \"someone\", \"us\", \"people\", \"anyone\"] \n",
    "\n",
    "pattern1 = [\n",
    "    {\"RIGHT_ID\": \"attr\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"kill\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern2 = [\n",
    "    {\"RIGHT_ID\": \"verb\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"want\", \"wish\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"verb\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"verb\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"xcomp\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"xcomp\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"xcomp\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carico spacy e aggiungo il pattern al Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"pattern1\", [pattern1])\n",
    "matcher.add(\"pattern2\", [pattern2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodi utili per trovare il match e per la wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match( text):\n",
    "    # Find the pattern in the document\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "        \n",
    "        return subj,dobj,phrase[0].tag_,phrase[len(phrase)-1].tag_\n",
    "    return \"\",\"\",\"\",\"\"\n",
    "\n",
    "def word_sense_disambiguation(list_words, word):\n",
    "    right_synset = lesk(list_words, word)\n",
    "    return right_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    res = text.split('.')\n",
    "    return res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('artifact', 'communication'): 1.16%\n",
      "('person', 'person'): 72.67%\n",
      "('person', 'group'): 1.16%\n",
      "('person', 'communication'): 2.91%\n",
      "('person', 'animal'): 3.49%\n",
      "('act', 'person'): 1.16%\n",
      "('person', 'all'): 4.65%\n",
      "('person', 'artifact'): 2.33%\n",
      "('cognition', 'person'): 1.74%\n",
      "('person', 'cognition'): 1.16%\n",
      "('person', 'act'): 1.16%\n",
      "('group', 'person'): 3.49%\n",
      "('person', 'emotion'): 1.74%\n",
      "('social', 'person'): 1.16%\n",
      "99.97999999999996\n"
     ]
    }
   ],
   "source": [
    "subj_ss = \"\"\n",
    "dobj_ss = \"\"\n",
    "struct = {}\n",
    "tot = 0\n",
    "c=0\n",
    "with open ('../sentence_kill.txt', 'r', encoding=\"utf8\") as f:\n",
    "    for row in f:\n",
    "        subj_synset, dobj_synset, subj_ss, dobj_ss = None, None, \"\", \"\"\n",
    "        subj, dobj, stag, dtag = get_match(row)\n",
    "            \n",
    "        if subj != \"\" and dobj != \"\":\n",
    "            # Cerco il synset del soggetto e dell'oggetto e associo automaticamente il synset \"person\" se trovo\n",
    "            # un nome proprio o una sringa presente in person\n",
    "            \n",
    "            # Soggetto\n",
    "            if stag == \"NNP\" or subj.lower() in person:\n",
    "                subj_ss = \"person\"\n",
    "            else:\n",
    "                subj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), subj)\n",
    "            # Oggetto\n",
    "            if dtag == \"NNP\" or dobj.lower() in person:\n",
    "                dobj_ss = \"person\"\n",
    "            else:\n",
    "                dobj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), dobj)        \n",
    "            \n",
    "            # Se subj_synset e' None, significa che abbiamo associato il synset person\n",
    "            if not subj_synset is None: \n",
    "                subj_ss = cleaner(subj_synset.lexname())\n",
    "            elif subj_ss != \"person\":\n",
    "                subj_ss = \"unknown\"\n",
    "            \n",
    "            # Soggetto\n",
    "            if not dobj_synset is None:\n",
    "                dobj_ss = cleaner(dobj_synset.lexname())  \n",
    "            elif dobj_ss != \"person\":\n",
    "                dobj_ss = \"unknown\"\n",
    "\n",
    "            # Oggetto\n",
    "            if (subj_ss, dobj_ss) in struct:\n",
    "                struct[(subj_ss, dobj_ss)] += 1\n",
    "            else:\n",
    "                struct[(subj_ss, dobj_ss)] = 1\n",
    "        else:\n",
    "            c+=1\n",
    "            #print(f\"phrase {c}: {row}\")\n",
    "\n",
    "for (k,v) in zip(struct.keys(),struct.values()):\n",
    "    if (k[0] != \"unknown\" and k[1] != \"unknown\") and v > 1:\n",
    "        tot += v\n",
    "\n",
    "for k in struct.keys():\n",
    "    if (k[0] != \"unknown\" and k[1] != \"unknown\") and struct[k] > 1:\n",
    "        print(f\"{k}: {round(((struct[k]/tot)*100), 2)}%\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ed4aba4c119105743730e2b96c2b24e70aa5572a8c25f5746c820738ee0ea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
