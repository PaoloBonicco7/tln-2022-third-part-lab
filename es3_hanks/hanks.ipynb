{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consegna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scegliere un verbo transitivo --> **KILL**\n",
    "- Trovare un corpus con > 1000 frasi in cui comprare un verbo scelto (usare un verbo comune) --> link to resource: https://sentence.yourdictionary.com/kill\n",
    "- Effettuare parsing e disambiguazione\n",
    "- Usare i supersensi di wordnet sugli argomenti (subj e obj nel caso di 2 argomenti) del verbo scelto\n",
    "- Calcolo risultati, frequenza e stampare cluster semantici ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande per il prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il modo in ci etichettiamo \"person\" alle parole va bene?\n",
    "- Il modo in cui disambiguiamo, per quanto poco efficiente (lesk), Ã¨ ok?\n",
    "- Va bene il modo in cui rappresentiamo i risultati (cluster semantici)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appunti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet supersense: Per ogni sinset abbiamo un supersenso associato (esempi su slide)\n",
    "Utilizzare i supersense dei synset per determinare il semantic type - nltk\n",
    "\n",
    "I supersense di wordenet non sono il massimo, vediamo alcune alternative:\n",
    " * CSI - Ai supersense ci sono associati delle categorie che possono essere utilizzati come supersense\n",
    "\n",
    "link to wordnet resource: https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html\n",
    "\n",
    "*Spunti futuri:*\n",
    "\n",
    "**Come distinguo i synset?**\n",
    "--> Funzione lesk (https://www.nltk.org/howto/wsd.html#word-sense-disambiguation)\n",
    "\n",
    "**Come trovo il supersenso tra due termini?**\n",
    "--> Funzione Lowest Common Hypernyms (https://www.nltk.org/howto/wordnet_lch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from nltk.wsd import lesk\n",
    "import re\n",
    "import spacy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* person: Usata per trovare il supersenso dei pronomi\n",
    "* patter: Usato per trovare il soggetto e l'oggetto del verbo kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = [\"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"me\", \"him\", \"her\", \"his\", \"them\", \"someone\", \"us\", \"people\", \"anyone\"] \n",
    "\n",
    "pattern = [\n",
    "    {\"RIGHT_ID\": \"attr\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"kill\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carico spacy e aggiungo il pattern al Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"pattern\", [pattern])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodi utili per trovare il match e per la wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match( text):\n",
    "    # Find the pattern in the document\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "        \n",
    "        return subj,dobj,phrase[0].tag_,phrase[len(phrase)-1].tag_\n",
    "    return \"\",\"\",\"\",\"\"\n",
    "\n",
    "def word_sense_disambiguation(list_words, word):\n",
    "    right_synset = lesk(list_words, word)\n",
    "    return right_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    res = text.split('.')\n",
    "    return res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Tops', 'person'): 1,\n",
      " ('act', 'cognition'): 1,\n",
      " ('act', 'person'): 2,\n",
      " ('all', 'food'): 1,\n",
      " ('animal', 'artifact'): 1,\n",
      " ('animal', 'quantity'): 1,\n",
      " ('artifact', 'act'): 1,\n",
      " ('artifact', 'all'): 1,\n",
      " ('artifact', 'communication'): 2,\n",
      " ('artifact', 'person'): 1,\n",
      " ('body', 'person'): 1,\n",
      " ('cognition', 'person'): 3,\n",
      " ('communication', 'food'): 1,\n",
      " ('communication', 'person'): 1,\n",
      " ('competition', 'artifact'): 1,\n",
      " ('contact', 'person'): 2,\n",
      " ('food', 'person'): 1,\n",
      " ('food', 'time'): 1,\n",
      " ('group', 'consumption'): 1,\n",
      " ('group', 'person'): 6,\n",
      " ('motion', 'person'): 1,\n",
      " ('person', 'act'): 2,\n",
      " ('person', 'all'): 8,\n",
      " ('person', 'animal'): 6,\n",
      " ('person', 'artifact'): 4,\n",
      " ('person', 'change'): 1,\n",
      " ('person', 'cognition'): 2,\n",
      " ('person', 'communication'): 4,\n",
      " ('person', 'emotion'): 2,\n",
      " ('person', 'food'): 1,\n",
      " ('person', 'group'): 3,\n",
      " ('person', 'person'): 108,\n",
      " ('person', 'stative'): 1,\n",
      " ('person', 'unknown'): 10,\n",
      " ('social', 'person'): 2,\n",
      " ('social', 'state'): 1,\n",
      " ('unknown', 'animal'): 2,\n",
      " ('unknown', 'consumption'): 1,\n",
      " ('unknown', 'person'): 10,\n",
      " ('unknown', 'plant'): 1}\n"
     ]
    }
   ],
   "source": [
    "subj_ss = \"\"\n",
    "dobj_ss = \"\"\n",
    "struct = {}\n",
    "with open ('../sentence_kill.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        subj_synset, dobj_synset, subj_ss, dobj_ss = None, None, \"\", \"\"\n",
    "        subj, dobj, stag, dtag = get_match(row)\n",
    "            \n",
    "        if subj != \"\" and dobj != \"\":\n",
    "            # Cerco il synset del soggetto e dell'oggetto e associo automaticamente il synset \"person\" se trovo\n",
    "            # un nome proprio o una sringa presente in person\n",
    "            \n",
    "            # Soggetto\n",
    "            if stag == \"NNP\" or subj.lower() in person:\n",
    "                subj_ss = \"person\"\n",
    "            else:\n",
    "                subj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), subj)\n",
    "            # Oggetto\n",
    "            if dtag == \"NNP\" or dobj.lower() in person:\n",
    "                dobj_ss = \"person\"\n",
    "            else:\n",
    "                dobj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), dobj)        \n",
    "                 \n",
    "            # Se subj_synset e' None, significa che abbiamo associato il synset person\n",
    "            if not subj_synset is None: \n",
    "                subj_ss = cleaner(subj_synset.lexname())\n",
    "            elif subj_ss != \"person\":\n",
    "                subj_ss = \"unknown\"\n",
    "            \n",
    "            # Soggetto\n",
    "            if not dobj_synset is None:\n",
    "                dobj_ss = cleaner(dobj_synset.lexname())    \n",
    "            elif dobj_ss != \"person\":\n",
    "                dobj_ss = \"unknown\"\n",
    "\n",
    "            # Oggetto\n",
    "            if (subj_ss, dobj_ss) in struct:\n",
    "                struct[(subj_ss, dobj_ss)] += 1\n",
    "            else:\n",
    "                struct[(subj_ss, dobj_ss)] = 1\n",
    "            \n",
    "for k in struct.keys():\n",
    "    print(f\"{k}: {round(((struct[k]/tot)*100), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecchio metodo che non etichettava i nomi propri correttamente (per fare comparazione di performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Tops', 'animal'): 1,\n",
      " ('act', 'cognition'): 1,\n",
      " ('act', 'person'): 3,\n",
      " ('all', 'all'): 2,\n",
      " ('all', 'animal'): 2,\n",
      " ('all', 'artifact'): 1,\n",
      " ('all', 'change'): 1,\n",
      " ('all', 'cognition'): 1,\n",
      " ('all', 'communication'): 1,\n",
      " ('all', 'food'): 1,\n",
      " ('all', 'group'): 1,\n",
      " ('all', 'location'): 1,\n",
      " ('all', 'person'): 14,\n",
      " ('animal', 'Tops'): 1,\n",
      " ('animal', 'artifact'): 1,\n",
      " ('animal', 'himself'): 1,\n",
      " ('animal', 'location'): 1,\n",
      " ('animal', 'person'): 3,\n",
      " ('animal', 'quantity'): 1,\n",
      " ('artifact', 'act'): 1,\n",
      " ('artifact', 'all'): 1,\n",
      " ('artifact', 'communication'): 2,\n",
      " ('artifact', 'person'): 1,\n",
      " ('body', 'person'): 1,\n",
      " ('cognition', 'location'): 1,\n",
      " ('cognition', 'person'): 2,\n",
      " ('communication', 'food'): 1,\n",
      " ('communication', 'person'): 1,\n",
      " ('competition', 'artifact'): 1,\n",
      " ('contact', 'person'): 2,\n",
      " ('czerno', 'location'): 1,\n",
      " ('food', 'person'): 1,\n",
      " ('food', 'time'): 1,\n",
      " ('group', 'animal'): 1,\n",
      " ('group', 'consumption'): 1,\n",
      " ('group', 'person'): 4,\n",
      " ('group', 'stative'): 1,\n",
      " ('jonny', 'person'): 2,\n",
      " ('kris.ll', 'person'): 1,\n",
      " ('location', 'animal'): 1,\n",
      " ('motion', 'artifact'): 1,\n",
      " ('person', 'Tops'): 1,\n",
      " ('person', 'act'): 2,\n",
      " ('person', 'all'): 4,\n",
      " ('person', 'animal'): 10,\n",
      " ('person', 'artifact'): 2,\n",
      " ('person', 'attribute'): 1,\n",
      " ('person', 'communication'): 1,\n",
      " ('person', 'connor'): 1,\n",
      " ('person', 'czerno'): 1,\n",
      " ('person', 'emotion'): 2,\n",
      " ('person', 'group'): 2,\n",
      " ('person', 'jonny'): 1,\n",
      " ('person', 'location'): 5,\n",
      " ('person', 'person'): 30,\n",
      " ('person', 'state'): 2,\n",
      " ('person', 'stative'): 3,\n",
      " ('person', 'substance'): 2,\n",
      " ('person', 'those'): 1,\n",
      " ('person', 'yourself'): 1,\n",
      " ('quantity', 'all'): 1,\n",
      " ('quantity', 'artifact'): 1,\n",
      " ('quantity', 'myself'): 1,\n",
      " ('quantity', 'person'): 3,\n",
      " ('said--', 'person'): 1,\n",
      " ('sirian', 'person'): 1,\n",
      " ('social', 'location'): 2,\n",
      " ('social', 'state'): 1,\n",
      " ('substance', 'Tops'): 1,\n",
      " ('substance', 'all'): 1,\n",
      " ('substance', 'animal'): 1,\n",
      " ('substance', 'artifact'): 1,\n",
      " ('substance', 'cognition'): 1,\n",
      " ('substance', 'communication'): 2,\n",
      " ('substance', 'damian'): 1,\n",
      " ('substance', 'food'): 1,\n",
      " ('substance', 'himself'): 1,\n",
      " ('substance', 'location'): 3,\n",
      " ('substance', 'marius'): 1,\n",
      " ('substance', 'others'): 3,\n",
      " ('substance', 'person'): 18,\n",
      " ('substance', 'state'): 1,\n",
      " ('substance', 'those'): 1,\n",
      " ('taran', 'person'): 1,\n",
      " ('that', 'person'): 2,\n",
      " ('that', 'plant'): 1,\n",
      " ('that', 'stative'): 1,\n",
      " ('this', 'person'): 1,\n",
      " ('what', 'animal'): 2,\n",
      " ('what', 'consumption'): 1,\n",
      " ('what', 'person'): 2,\n",
      " ('which', 'animal'): 1,\n",
      " ('which', 'substance'): 1}\n"
     ]
    }
   ],
   "source": [
    "def get_match_2( text):\n",
    "    # Find the pattern in the document\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "        \n",
    "        return subj,dobj\n",
    "    return \"\",\"\"\n",
    "\n",
    "subj_ss = \"\"\n",
    "dobj_ss = \"\"\n",
    "struct = {}\n",
    "with open ('../sentence_kill.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        subj_ss, dobj_ss = \"\", \"\"\n",
    "        subj, dobj = get_match_2(row)\n",
    "        if subj != \"\" and dobj != \"\":\n",
    "            subj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), subj)\n",
    "            dobj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), dobj)\n",
    "            \n",
    "            if not subj_synset is None: \n",
    "                subj_ss = cleaner(subj_synset.lexname())\n",
    "            else:\n",
    "                if subj.lower() in person:\n",
    "                    subj_ss = \"person\"\n",
    "                else:\n",
    "                    subj_ss = subj.lower()\n",
    "            if not dobj_synset is None:\n",
    "                dobj_ss = cleaner(dobj_synset.lexname())    \n",
    "            else:\n",
    "                if dobj.lower() in person:\n",
    "                    dobj_ss = \"person\"\n",
    "                else:\n",
    "                    dobj_ss = dobj.lower()\n",
    "\n",
    "            if (subj_ss, dobj_ss) in struct:\n",
    "                struct[(subj_ss, dobj_ss)] += 1\n",
    "            else:\n",
    "                struct[(subj_ss, dobj_ss)] = 1\n",
    "            \n",
    "pprint(struct)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
