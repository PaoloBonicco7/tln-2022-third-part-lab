{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consegna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scegliere un verbo transitivo --> **KILL**\n",
    "- Trovare un corpus con > 1000 frasi in cui comprare un verbo scelto (usare un verbo comune) --> link to resource: https://sentence.yourdictionary.com/kill\n",
    "- Effettuare parsing e disambiguazione\n",
    "- Usare i supersensi di wordnet sugli argomenti (subj e obj nel caso di 2 argomenti) del verbo scelto\n",
    "- Calcolo risultati, frequenza e stampare cluster semantici ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appunti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet supersense: Per ogni sinset abbiamo un supersenso associato (esempi su slide)\n",
    "Utilizzare i supersense dei synset per determinare il semantic type - nltk\n",
    "\n",
    "I supersense di wordenet non sono il massimo, vediamo alcune alternative:\n",
    " * CSI - Ai supersense ci sono associati delle categorie che possono essere utilizzati come supersense\n",
    "\n",
    "link to wordnet resource: https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html\n",
    "\n",
    "*Spunti futuri:*\n",
    "\n",
    "**Come distinguo i synset?**\n",
    "--> Funzione lesk (https://www.nltk.org/howto/wsd.html#word-sense-disambiguation)\n",
    "\n",
    "**Come trovo il supersenso tra due termini?**\n",
    "--> Funzione Lowest Common Hypernyms (https://www.nltk.org/howto/wordnet_lch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordnet - Esempi di utilizzo di funzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print(f\"synsets di subj: {wordnet.synsets(subj)}; synsets di obj: {wordnet.synsets(obj)}\\n\\n\")\n",
    "#print(f\"iperonimo di subj: {wordnet.synsets(subj)[0].hypernyms()}, iperonimo di obj: {wordnet.synsets(obj)[0].hypernyms()}\\n\\n\")\n",
    "        \n",
    "print(wordnet.synsets(\"monkey\"))\n",
    "print(wordnet.synsets(\"victor\")[0].supersense())\n",
    "print(wordnet.synsets(\"monkey\")[0].definition())\n",
    "print(wordnet.synsets(\"monkey\")[0].hyponyms())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(wordnet.synsets(\"banana\")[0].common_hypernyms(wordnet.synsets(\"monkey\")[0]))\n",
    "print(wordnet.synsets(\"dog\")[0].root_hypernyms())\n",
    "print(f\"antenato più vicino tra man e baby: {wordnet.synsets('man')[0].lowest_common_hypernyms(wordnet.synsets('baby')[0])}\") # UTILE UTILE UTILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from spacy.matcher import DependencyMatcher\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* person: Usata per trovare il supersenso dei pronomi\n",
    "* patter: Usato per trovare il soggetto e l'oggetto del verbo kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = [\"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"me\", \"her\", \"his\", \"them\", \"someone\"] \n",
    "\n",
    "pattern = [\n",
    "    {\"RIGHT_ID\": \"attr\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"kill\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(name_pattern, pattern, text):\n",
    "    # Find the pattern in the document\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    matched_elements = [] \n",
    "    matcher = DependencyMatcher(nlp.vocab)\n",
    "    matcher.add(name_pattern, [pattern])\n",
    "    doc = nlp(text.lower())\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x : x[1]) #* Probably not needed\n",
    "    \n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "\n",
    "\n",
    "        super_subj, super_dobj = \"\", \"\"\n",
    "        if subj in person:\n",
    "            super_subj = \"Person\"\n",
    "        elif dobj in person:\n",
    "            super_dobj = \"Person\"\n",
    "        \n",
    "        syn_subj = wordnet.synsets(subj)\n",
    "        syn_dobj = wordnet.synsets(dobj)\n",
    "        \n",
    "        if syn_subj == []:\n",
    "            print(f\"Frase: {text}\")\n",
    "            print(f\"Synset non trovato, il soggetto è {subj}\")\n",
    "        elif syn_dobj == []:\n",
    "            print(f\"Frase: {text}\")\n",
    "            print(f\"Synset non trovato, l'oggetto' è {dobj}\")\n",
    "        else:\n",
    "            syn_subj = syn_subj\n",
    "            syn_dobj = syn_dobj\n",
    "        '''\n",
    "        if super_subj != \"\":\n",
    "            print(f\"S:{subj}: {super_subj}\")\n",
    "        else:\n",
    "            print(f\"{subj}: {syn_subj}\")\n",
    "        \n",
    "        if super_dobj != \"\":\n",
    "            print(f\"S:{dobj}: {super_dobj}\")\n",
    "        else:\n",
    "            print(f\"{dobj}: {syn_dobj}\")\n",
    "        '''\n",
    "        #matched_elements.append(wordnet.synsets(subj)[0].supersense() ,wordnet.synsets(dobj)[0].supersense())\n",
    "    if matched_elements == []:\n",
    "        return False\n",
    "    return matched_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open ('../sentence_kill.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        result = get_match(\"pattern\", pattern, row)\n",
    "        if result != False:\n",
    "            dataset.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test \n",
    "Utilizzato per codice di prova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo che cerca un match con il pattern riportato sopra. \n",
    "Il match che trova è del tipo (\"soggetto kill oggetto\"), tramite l'accesso alla prima e all'ultima parola riusciamo ad isolare soggetto e oggetto.\n",
    "Controlliamo se uno dei due (o entrambi) sono presenti nella lista sopra dichiarata, nel caso lo siano, sappiamo già che il loro \"supersense\" (o iperonimo, dobbiamo capire) è Person.\n",
    "\n",
    "Due problematiche:\n",
    "- nel caso in cui abbiamo più di un synset per ogni parola dobbiamo disambiguare e capire quale prendere.\n",
    "- nel caso ci siano altre parole (Others, nomi di persona,...) che non hanno un synset, dobbiamo capire come gestirli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(name_pattern, pattern, text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    matched_elements = [] \n",
    "    matcher = DependencyMatcher(nlp.vocab)\n",
    "    matcher.add(name_pattern, [pattern])\n",
    "    doc = nlp(text.lower())\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x : x[1])\n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "\n",
    "\n",
    "        super_subj, super_dobj = \"\", \"\"\n",
    "        if subj in person:\n",
    "            super_subj = \"Person\"\n",
    "        elif dobj in person:\n",
    "            super_dobj = \"Person\"\n",
    "        \n",
    "        syn_subj = wordnet.synsets(subj)\n",
    "        syn_dobj = wordnet.synsets(dobj)\n",
    "        \n",
    "        if syn_subj == []:\n",
    "            print(f\"Frase: {text}\")\n",
    "            print(f\"Synset non trovato, il soggetto è {subj}\")\n",
    "        elif syn_dobj == []:\n",
    "            print(f\"Frase: {text}\")\n",
    "            print(f\"Synset non trovato, l'oggetto' è {dobj}\")\n",
    "        else:\n",
    "            syn_subj = syn_subj\n",
    "            syn_dobj = syn_dobj\n",
    "        '''\n",
    "        if super_subj != \"\":\n",
    "            print(f\"S:{subj}: {super_subj}\")\n",
    "        else:\n",
    "            print(f\"{subj}: {syn_subj}\")\n",
    "        \n",
    "        if super_dobj != \"\":\n",
    "            print(f\"S:{dobj}: {super_dobj}\")\n",
    "        else:\n",
    "            print(f\"{dobj}: {syn_dobj}\")\n",
    "        '''\n",
    "        #matched_elements.append(wordnet.synsets(subj)[0].supersense() ,wordnet.synsets(dobj)[0].supersense())\n",
    "    if matched_elements == []:\n",
    "        return False\n",
    "    return matched_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE AND NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono soggetti e oggetti che non hanno dei synset, ad esempio YOU non ha un wordnet synset, credo che si debbano eliminare dal dataset questi tipi di frase, perchè non si possono trovare gli iperonimi se non hai il synset di partenza. in alternativa, come ha detto il prof a lezione, si può mettere una regola per cui quando incontri uno di questi elementi metti 'person' come iperonimo di default\n",
    "\n",
    "IL DATASET HA UN BOTTO DI SOGGETTI E OGGETTI CON PRONOMI DI MERDA. UN PÒ BRUTTINO PER I NOSTRI SCOPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open ('../sentence_cook.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        result = get_match(\"pattern\", pattern, row)\n",
    "        if result != False:\n",
    "            dataset.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cose utili sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"synsets di subj: {wordnet.synsets(subj)}; synsets di obj: {wordnet.synsets(obj)}\\n\\n\")\n",
    "#print(f\"iperonimo di subj: {wordnet.synsets(subj)[0].hypernyms()}, iperonimo di obj: {wordnet.synsets(obj)[0].hypernyms()}\\n\\n\")\n",
    "        \n",
    "print(wordnet.synsets(\"monkey\"))\n",
    "print(wordnet.synsets(\"victor\")[0].supersense())\n",
    "print(wordnet.synsets(\"monkey\")[0].definition())\n",
    "print(wordnet.synsets(\"monkey\")[0].hyponyms())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(wordnet.synsets(\"banana\")[0].common_hypernyms(wordnet.synsets(\"monkey\")[0]))\n",
    "print(wordnet.synsets(\"dog\")[0].root_hypernyms())\n",
    "print(f\"antenato più vicino tra man e baby: {wordnet.synsets('man')[0].lowest_common_hypernyms(wordnet.synsets('baby')[0])}\") # UTILE UTILE UTILE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fc711e4ee2b6550a1e55fb58a23702f691a325dedbbea2e10fa55c056de4b98"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvdicaro': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
