{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet supersense: Per ogni sinset abbiamo un supersenso associato (esempi su slide)\n",
    "Utilizzare i supersense dei synset per determinare il semantic type - nltk\n",
    "\n",
    "I supersense di wordenet non sono il massimo, vediamo alcune alternative:\n",
    " * CSI - Ai supersense ci sono associati delle categorie che possono essere utilizzati come supersense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio\n",
    "- Scegliere un verbo transitivo\n",
    "- Trovare un corpus con > 1000 frasi in cui comprare un verbo scelto (usare un verbo comune)\n",
    "- Effettuare parsing e disambiguazione\n",
    "- Usare i supersensi di wordnet sugli argomenti (subj e obj nel caso di 2 argomenti) del verbo scelto\n",
    "- Calcolo risultati, frequenza e stampare cluster semantici ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to resource: https://sentence.yourdictionary.com/kill\n",
    "\n",
    "link to wordnet resource: https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### individuazione soggetto e oggetto in una frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_obj(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    subj = \"\"\n",
    "    obj = \"\"\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj':\n",
    "            subj = token.text\n",
    "        if token.dep_ == 'dobj':\n",
    "            obj = token.text\n",
    "    return [subj, obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea:\n",
    "Per ogni riga salvare iperonimi di subj e obj (se ne ho più di uno sceglierne uno, ma quale?).\n",
    "Una volta salvati gli iperonimi, accorpo quelli uguali in dei cluster (singolarmente tra soggetti e oggetti) infine stampo i cluster come \"Cluster_subj KILLS Cluster_obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problema: \n",
    "Ci sono soggetti e oggetti che non hanno dei synset, ad esempio YOU non ha un wordnet synset, credo che si debbano eliminare dal dataset questi tipi di frase, perchè non si possono trovare gli iperonimi se non hai il synset di partenza. in alternativa, come ha detto il prof a lezione, si può mettere una regola per cui quando incontri uno di questi elementi metti 'person' come iperonimo di default\n",
    "\n",
    "IL DATASET HA UN BOTTO DI SOGGETTI E OGGETTI CON PRONOMI DI MERDA. UN PÒ BRUTTINO PER I NOSTRI SCOPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open ('../sentence_cook.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        # subj, obj = get_subj_obj(row)\n",
    "        #print(f\"{row}   subj is: {subj}; obj is: {obj}.\")\n",
    "        #print(f\"synsets di subj: {wordnet.synsets(subj)}; synsets di obj: {wordnet.synsets(obj)}\\n\\n\")\n",
    "        #print(f\"iperonimo di subj: {wordnet.synsets(subj)[0].hypernyms()}, iperonimo di obj: {wordnet.synsets(obj)[0].hypernyms()}\\n\\n\")\n",
    "        dataset.append(get_subj_obj(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "for i in range(dataset):\n",
    "    print(wordnet.synsets(dataset[i][0].hypernyms()))\n",
    "    print(wordnet.synsets(dataset[i][1].hypernyms()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cose utili sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('monkey.n.01'), Synset('imp.n.02'), Synset('tamper.v.01'), Synset('putter.v.02')]\n",
      "[Synset('primate.n.02')]\n",
      "any of various long-tailed primates (excluding the prosimians)\n",
      "[Synset('new_world_monkey.n.01'), Synset('old_world_monkey.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Synset('entity.n.01'), Synset('object.n.01'), Synset('organism.n.01'), Synset('physical_entity.n.01'), Synset('living_thing.n.01'), Synset('whole.n.02')]\n",
      "[Synset('entity.n.01')]\n",
      "antenato più vicino tra man e baby: [Synset('person.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(wordnet.synsets(\"monkey\"))\n",
    "print(wordnet.synsets(\"monkey\")[0].hypernyms())\n",
    "print(wordnet.synsets(\"monkey\")[0].definition())\n",
    "print(wordnet.synsets(\"monkey\")[0].hyponyms())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(wordnet.synsets(\"banana\")[0].common_hypernyms(wordnet.synsets(\"monkey\")[0]))\n",
    "print(wordnet.synsets(\"dog\")[0].root_hypernyms())\n",
    "print(f\"antenato più vicino tra man e baby: {wordnet.synsets('man')[0].lowest_common_hypernyms(wordnet.synsets('baby')[0])}\") # UTILE UTILE UTILE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
